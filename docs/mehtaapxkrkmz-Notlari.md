# VERÄ° BÄ°LÄ°MÄ°NE GÄ°RÄ°Å

Veri Bilimi: Veriyi toplama,temizleme,analiz etme ve ondan anlamlÄ± sonuÃ§lar Ã§Ä±karma sÃ¼recini ifade eder.Bu disiplin; matematik,istatistik,bilgisayar bilimi ve alan bilgisi gibi birÃ§ok farklÄ± dalÄ±n birleÅŸiminden oluÅŸur.
- Veri bilimi,bÃ¼yÃ¼k veri setlerini anlamlandÄ±rarak iÅŸ kararlarÄ±nÄ± gÃ¼Ã§lendirme,mÃ¼ÅŸteri davranÄ±ÅŸlarÄ±nÄ± anlama veya bilimsel araÅŸtÄ±rmalar yÃ¼rÃ¼tme gibi birÃ§ok amaca hizmet eder.
Veri bilimi sÃ¼reci; veri toplama,veri Ã¶n iÅŸleme,model oluÅŸturma,model deÄŸerlendirme ve sonuÃ§ sunma aÅŸamalarÄ±ndan oluÅŸur.

Veri: Ham,iÅŸlenmemiÅŸ ve anlamsÄ±z bilgi parÃ§acÄ±klarÄ±dÄ±r.Ã–rneÄŸin bir web sitesinin ziyaretÃ§i sayÄ±sÄ±,anket sonuÃ§larÄ±,bir sensÃ¶rden alÄ±nan Ã¶lÃ§Ã¼mler "veri"dir.
Bilgi: Verinin belirli bir baÄŸlama yerleÅŸtirilmesi ve anlaÅŸÄ±labilir hale gelmesi ile oluÅŸur.
Ä°Ã§gÃ¶rÃ¼: Bilgiyi derinlemesine analiz ederek ve belirli kalÄ±plar keÅŸfederek elde edilen deÄŸerli sonuÃ§lardÄ±r. Ã–rneÄŸin mÃ¼ÅŸterilerin hangi Ã¼rÃ¼nleri hangi koÅŸullarda daha Ã§ok satÄ±n aldÄ±ÄŸÄ±nÄ± anlamak.

NOT: Ä°Ã§gÃ¶rÃ¼ doÄŸuÅŸtan deÄŸil verilerden gelir.

# Veri Bilimi AlanÄ±nda KullanÄ±lan AraÃ§lar
1. Programlama Dilleri: Python,kullanÄ±m kolaylÄ±ÄŸÄ± ve geniÅŸ kÃ¼tÃ¼phane desteÄŸi avantajlarÄ±yla veri bilimciler arasÄ±nda popÃ¼lerdir.R dili de veri biliminde kullanÄ±lmaktadÄ±r.
2. Veri GÃ¶rselleÅŸtirme AraÃ§larÄ±: Matplotlib,Seaborn,Plotly gibi Python kÃ¼tÃ¼phaneleri;Tableau,Power BI gibi gÃ¶rselleÅŸtirme araÃ§larÄ± veriyi gÃ¶rselleÅŸtirerek iÃ§gÃ¶rÃ¼lerin daha anlaÅŸÄ±lÄ±r olmasÄ±nÄ± saÄŸlar.
3. Veri Analiz AraÃ§larÄ±: Pandas ve Numpy,veri analizi ve manipÃ¼lasyonu iÃ§in kullanÄ±lan gÃ¼Ã§lÃ¼ kÃ¼tÃ¼phanelerdir.Jupyter Notebook;kodlama,analiz yapma,sonuÃ§larÄ± belgeler halinde saklama aÃ§Ä±sÄ±ndan Ã¶nemli bir araÃ§tÄ±r.
4. Makine Ã–ÄŸrenmesi KÃ¼tÃ¼phaneleri: Scikit-learn,TensorFlow,Keras gibi kÃ¼tÃ¼phaneler;model oluÅŸturma,eÄŸitme ve geliÅŸtirme sÃ¼reÃ§lerinde kullanÄ±lÄ±r.

Veri bilimi,veri analitiÄŸinden farklÄ± olarak TAHMÄ°NLEME de yapar.

Model,bir desendir.AmacÄ±mÄ±z verideki desenleri yakalamaya Ã§alÄ±ÅŸmak.Makineye birÃ§ok veri veriyoruz.Makine buradan desen Ã§Ä±karÄ±yor.Ä°ÅŸte buna makine Ã¶ÄŸrenmesi denir.

Yapay zeka asla bilmez,sadece tahmin eder -> Next Token Prediction
Yapay zeka modeli parametrelerden oluÅŸur ve bu parametrelerin nasÄ±l kullanÄ±ldÄ±ÄŸÄ± bu modelin iÃ§indedir.
Yapay zeka modeli,hesap mkakinesiyle bulunamayan ve tecrÃ¼beye dayanan verilerden oluÅŸur.

HalÃ¼sinasyon: Yapay zekanÄ±n yanlÄ±ÅŸ yaptÄ±ÄŸÄ± bilgidir.
Yapay zeka,makine Ã¶ÄŸrenmesinin daha da Ã¼stÃ¼ndedir.

Model: KurallarÄ±n ve parametrelerin bir bÃ¼tÃ¼n olarak bulunmasÄ±dÄ±r.HiÃ§bir makine Ã¶ÄŸrenmesi modeli %100 bilmez.

kayÄ±p miktarÄ±=cost(loss) function
W=weight=parametre

## RELU Aktivasyon Fonksiyonu: 0'Ä±n altÄ±ndaki tÃ¼m sayÄ±larÄ± sÄ±fÄ±rlar.0'Ä±n Ã¼stÃ¼ndekilere dokunmaz.

HatalarÄ±n yÃ¶nleri(negatif/pozitif)Ã¶nemli.Bu yÃ¼zden hatalarÄ±n karelerini alacaÄŸÄ±z.[Mean Squared Error(MSE)]

### Softmax Fonksiyonu: Verilen sayÄ±larÄ±n toplamÄ± 1 olacak ÅŸekilde iÅŸleme sokar.
### Sigmoid Fonksiyonu: verilen bÃ¼tÃ¼n sayÄ±larÄ± 0 ve 1 arasÄ±na yerleÅŸtirir. Ã–rn : 16/17 gibi saÄŸ taraf,sol taraftaki sayÄ±dan 1 fazla olacak.

Boyut (Dimension) genellikle veri kÃ¼mesindeki Ã¶zellik (Feature) sayÄ±sÄ±nÄ± ifade eder.Ã–rneÄŸin: bir veri kÃ¼mesinde yaÅŸ, maaÅŸ, eÄŸitim seviyesi gibi 3 Ã¶zellik varsa, veri 3 boyutludur.

Feature(Ã–zellik): Veri setindeki sÃ¼tunlardÄ±r.Ã–zellik sayÄ±sÄ± arttÄ±kÃ§a daha fazla detay olur ancak iÅŸlem sayÄ±sÄ± artar.

## Makine Ã–ÄŸrenmesi ve Geleneksel ProgramlamanÄ±n FarkÄ±
-> Makine,Ã§arpma iÅŸlemi yapacaÄŸÄ±nÄ± asla Ã¶ÄŸrenmez.Biz makineye iÅŸlemi vermeliyiz.
-> Geleneksel programlamada ise neyle Ã§arpÄ±m yapacaÄŸÄ±nÄ± biliyoruz.
-> Makine Ã¶ÄŸrenmesinde verilen Ã¶rÃ¼ntÃ¼den yararlanÄ±lÄ±yor.Makine; bu iÅŸlemlerde kullanacaÄŸÄ± sayÄ±yÄ± yani "parametre"yi Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±yor.
Makine Ã¶ÄŸrenmesi modeli; makine Ã¶ÄŸrenmesi algoritmalsÄ± ve algoritmada kullanÄ±lan deÄŸer/deÄŸerlerden oluÅŸur.

## Lineer Regresyon 
Denklem her zaman y=ax+b ÅŸeklindedir.BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (Ã¶zellikler) ile baÄŸÄ±mlÄ± deÄŸiÅŸken (hedef) arasÄ±ndaki doÄŸrusal iliÅŸkiyi modelleyen bir regresyon tekniÄŸidir. Lineer regresyon, basit ve yorumlanabilir olmasÄ±yla veri bilimi ve makine Ã¶ÄŸrenmesinde temel bir modeldir. 
Ã–zetle lineer regresyon,doÄŸru Ã§izerek Ã§Ã¶zÃ¼lebilen regresyon problemleridir.Fakat sadece lineer regresyonla Ã§Ã¶zÃ¼lebilen problem sayÄ±sÄ± gerÃ§ek dÃ¼nyada oldukÃ§a azdÄ±r.

## K-Means AlgoritmasÄ±
K-Means algoritmasÄ±, veri noktalarÄ±nÄ± K adet kÃ¼meye ayÄ±ran bir kÃ¼meleme (clustering) yÃ¶ntemidir.
Unsupervised(gÃ¶zetimsiz)learning algoritmalarÄ±ndandÄ±r.

### K-Means AlgoritmasÄ±nÄ±n AdÄ±mlarÄ±:
1. BaÅŸlangÄ±Ã§ta K adet merkez (centroid) rastgele seÃ§ilir.
2. Her veri noktasÄ±, en yakÄ±n merkeze atanÄ±r.
3. Her kÃ¼me iÃ§in yeni merkezler, kÃ¼medeki noktalarÄ±n ortalamasÄ± alÄ±narak gÃ¼ncellenir.
4. AdÄ±mlar tekrar edilir (kÃ¼me merkezleri deÄŸiÅŸmeyene veya belirli bir iterasyon sayÄ±sÄ±na ulaÅŸÄ±lana kadar).

K deÄŸeri Ã¶nceden belirlenmelidir.
K-means, Ã–klid mesafesini kullanarak noktalarÄ± gruplar.

Regresyon: SayÄ± veririm,bana sayÄ± verir(numeric to numeric).GeÃ§miÅŸ verilerden Ã¶ÄŸrenir.
SÄ±nÄ±flandÄ±rma Problemleri:GruplarÄ±n bir ismi var.
KÃ¼meleme Problemleri:GruplarÄ±n bir ismi  yok.

NOT: Next token prediction bir tÃ¼r sÄ±nÄ±flandÄ±rma problemidir.
Model, bir dizideki sonraki token'Ä± belirlemeye Ã§alÄ±ÅŸÄ±rken tÃ¼m kelime haznesi (vocabulary) iÃ§indeki olasÄ±lÄ±klarÄ± hesaplar.
Her token bir sÄ±nÄ±f gibi dÃ¼ÅŸÃ¼nÃ¼lebilir.
Model, en yÃ¼ksek olasÄ±lÄ±ÄŸa sahip tokenâ€™Ä± seÃ§erek sÄ±nÄ±flandÄ±rma yapar.

Ã–rneÄŸin:
EÄŸer bir dil modeli "Ben kahve iÃ§mek..." ifadesini gÃ¶rÃ¼yorsa, sonraki kelimenin "istiyorum" olma olasÄ±lÄ±ÄŸÄ± 0.85, "sevmem" olma olasÄ±lÄ±ÄŸÄ± 0.10, "yapÄ±yorum" olma olasÄ±lÄ±ÄŸÄ± 0.05 olabilir.
Model, en yÃ¼ksek olasÄ±lÄ±ÄŸa sahip olan "istiyorum" kelimesini tahmin eder.
Softmax gibi olasÄ±lÄ±ksal yÃ¶ntemler kullanÄ±lÄ±r.

ğŸ”¹ Geleneksel sÄ±nÄ±flandÄ±rmada genellikle sabit Ã¶zellikler Ã¼zerinden sÄ±nÄ±flandÄ±rma yapÄ±lÄ±rken, Next Token Prediction'da girdi dinamik olarak deÄŸiÅŸir.
ğŸ”¹ Ã–nceki token'lar, sonraki token tahminini etkiler.
ğŸ”¹ GPT, BERT gibi Transformer tabanlÄ± dil modelleri bu yÃ¶ntemi kullanarak Ã¶ÄŸrenir.

## Lojistik Regresyon

Lojistik regresyon, ikili (binary) ya da Ã§ok sÄ±nÄ±flÄ± (multiclass) sÄ±nÄ±flandÄ±rma problemlerinde kullanÄ±lan istatistiksel bir yÃ¶ntemdir. 
Regresyon kelimesi geÃ§se de temelde bir sÄ±nÄ±flandÄ±rma algoritmasÄ±dÄ±r.
BaÄŸÄ±mlÄ± deÄŸiÅŸkenin kategorik olduÄŸu durumlarda kullanÄ±lan bir istatistiksel modeldir.
2 faktÃ¶r vardÄ±r(BaÄŸÄ±mlÄ± deÄŸiÅŸken yalnÄ±zca 2 kategoriye sahiptir.).
Birinin deÄŸerini tahmin etmek iÃ§in bu iliÅŸkiyi kullanÄ±r. "Evet/hayÄ±r" gibi sÄ±nÄ±rlÄ± tahmin sonucu vardÄ±r.
Tahmin edilen sonucu 0 ve 1 arasÄ±nda sÄ±nÄ±rlandÄ±rmak iÃ§in sigmoid fonksiyonunu kullanÄ±r.y'yi x'in sigmoid fonksiyonu olarak eÅŸler.

Ïƒ(z)=1/(1+e^-z)
Ïƒ(z) â†’ Ã‡Ä±ktÄ±yÄ± olasÄ±lÄ±ÄŸa dÃ¶nÃ¼ÅŸtÃ¼ren sigmoid fonksiyonu
p(eÅŸik deÄŸeri)genelde 0.5'tir.EÄŸer Ã§Ä±ktÄ± 0.5â€™ten bÃ¼yÃ¼kse "1", kÃ¼Ã§Ã¼kse "0" olarak sÄ±nÄ±flandÄ±rÄ±lÄ±r.

Ã¶rn:Bir e-postanÄ±n spam olup olmadÄ±ÄŸÄ±nÄ± belirleme (Ã‡Ä±ktÄ±: "Spam" veya "Spam deÄŸil")

## KÃ¼meleme(Clustering)

KÃ¼meleme, verileri benzerliklerine gÃ¶re gruplara (kÃ¼melere) ayÄ±ran bir gÃ¶zetimsiz Ã¶ÄŸrenme yÃ¶ntemidir.

Ã–rnekleri: 
### 1.K-Means KÃ¼meleme:

KÃ¼me sayÄ±sÄ± (K) baÅŸtan belirlenir.
NOT:K'nÄ±n max deÄŸeri,veri sayÄ±sÄ± kadar olabilir.
Veri noktalarÄ±, en yakÄ±n kÃ¼me merkezine (centroid) atanÄ±r.
KÃ¼me merkezleri gÃ¼ncellenerek iÅŸlem tekrar edilir.
Ã–rnek kullanÄ±m: MÃ¼ÅŸteri segmentasyonu, anomali tespiti

### 2. HiyerarÅŸik KÃ¼meleme:

n tane birey,n tane kÃ¼me olmak Ã¼zere iÅŸlemlere baÅŸlanÄ±r.
Verileri birbirine benzer olan kÃ¼Ã§Ã¼k gruplara ayÄ±rarak zamanla bu gruplarÄ± birleÅŸtirir ve kÃ¼meleme yapar.
Veri setindeki benzerlikleri ortaya Ã§Ä±karÄ±r.
KÃ¼Ã§Ã¼k kÃ¼meler oluÅŸturulur ve bunlar zamanla daha bÃ¼yÃ¼k kÃ¼melerle birleÅŸtirilir (agglomerative).
Agglomerative(birleÅŸtirici) ve divisive(bÃ¶lÃ¼cÃ¼) yÃ¶ntemler ile uygulanabilir.
BaÅŸlangÄ±Ã§ta tÃ¼m nesneler birbirinden ayrÄ±.Her bir veriyi ayrÄ± bir kÃ¼me olarak kabul ediyoruz.Benzer Ã¶zelliklere sahip kÃ¼melere birleÅŸtiriyoruz.(TÃ¼mevarÄ±m)
Ya da bÃ¼yÃ¼k bir kÃ¼me alÄ±nÄ±r ve bÃ¶lÃ¼nerek alt kÃ¼melere ayrÄ±lÄ±r (divisive).
HiyerarÅŸik kÃ¼meleme, verileri gruplandÄ±rÄ±rken bir aÄŸacÄ±n (dendrogram) ÅŸeklinde hiyerarÅŸik bir yapÄ± oluÅŸturur.
BaÅŸlangÄ±Ã§ta her eleman bir kÃ¼me olsun.Burada mesafe=0'dÄ±r.ArdÄ±ndan mesafe=1 olan her eleman bir kÃ¼medir.Bu ÅŸekilde mesafeyi artÄ±ra artÄ±ra ilerliyoruz.
Ã–rnek kullanÄ±m: Genetik veri analizi, sosyal aÄŸ analizi

### Ä°ki kÃ¼meleme yÃ¶nteminin farklarÄ±
KÃ¼meleme: KÃ¼me sayÄ±sÄ± Ã¶nceden belirlenir ve veriler sabit sayÄ±da kÃ¼meye ayrÄ±lÄ±r.
HiyerarÅŸik KÃ¼meleme: KÃ¼me sayÄ±sÄ± baÅŸlangÄ±Ã§ta belirsizdir ve veriler hiyerarÅŸik bir yapÄ±ya gÃ¶re kÃ¼melenir, sonuÃ§ta bir aÄŸaÃ§ yapÄ±sÄ± elde edilir.
KÃ¼meleme problemleri genelde gÃ¶zetimsiz Ã¶ÄŸrenme.SÄ±nÄ±flandÄ±rma problemleri ise genellikle gÃ¶zetimli Ã¶ÄŸrenmedir.

### KÃ¼melemede kategorik veriler bulunabilir mi?

Evet, kÃ¼melemede kategorik veriler kullanÄ±labilir, ancak doÄŸrudan Ã–klid mesafesi gibi sayÄ±sal yÃ¶ntemlerle iÅŸlenemezler. 
Bu yÃ¼zden kategorik verileri uygun bir ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rmek veya kategorik verilerle Ã§alÄ±ÅŸabilen Ã¶zel algoritmalar kullanmak gerekir.

Kategorik verilerle Ã§alÄ±ÅŸma yÃ¶ntemleri nelerdir?
1. Kategorik Verileri SayÄ±sal Hale Getirme
EÄŸer kÃ¼melemede K-Means gibi sayÄ±sal verilerle Ã§alÄ±ÅŸan algoritmalar kullanÄ±lacaksa, kategorik veriler Ã¶nce dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmelidir:

âœ… One-Hot Encoding
Her kategori iÃ§in ayrÄ± bir sÃ¼tun oluÅŸturur.
Ã–rnek:
Renk: ["KÄ±rmÄ±zÄ±", "Mavi", "YeÅŸil"]
DÃ¶nÃ¼ÅŸtÃ¼rme:
KÄ±rmÄ±zÄ±	Mavi	YeÅŸil
1	    0	      0
0	    1	      0
0	    0	      1

âœ… Label Encoding
Her kategoriye bir sayÄ± atanÄ±r (Ã¶rn: KÄ±rmÄ±zÄ± â†’ 0, Mavi â†’ 1, YeÅŸil â†’ 2).

âœ… OrtaklÄ±k (Frequency) veya Hedef Kodlama (Target Encoding)
Kategorilerin veri iÃ§indeki frekansÄ±na veya hedef deÄŸiÅŸkenle iliÅŸkisine gÃ¶re sayÄ±sal deÄŸer atanÄ±r.
Ã–rnek: EÄŸer "Araba MarkasÄ±" Ã¶zelliÄŸinde Toyota %30, BMW %50, Ford %20 oranÄ±nda geÃ§iyorsa, bu oranlar kullanÄ±labilir.

NOT:NÃ¼merik veriler sÄ±ralanabilir,birbirine bÃ¶lÃ¼nebilir vb. Fakat kategorik verilerde bu,mÃ¼mkÃ¼n deÄŸildir.

### KÃ¼melemede cluster sayÄ±sÄ± nasÄ±l belirlenir?

KÃ¼meleme algoritmalarÄ±nda doÄŸru kÃ¼me sayÄ±sÄ±nÄ± (K) belirlemek kritik bir adÄ±mdÄ±r. 
EÄŸer K Ã§ok kÃ¼Ã§Ã¼kse kÃ¼meler anlamlÄ± olmayabilir, Ã§ok bÃ¼yÃ¼kse aÅŸÄ±rÄ± bÃ¶lÃ¼nmÃ¼ÅŸ kÃ¼meler oluÅŸabilir.

Dirsek (Elbow) YÃ¶ntemi
KÃ¼me sayÄ±sÄ± arttÄ±kÃ§a kÃ¼meler iÃ§indeki veri noktalarÄ±nÄ±n birbirine olan yakÄ±nlÄ±ÄŸÄ± artar (iÃ§sel tutarlÄ±lÄ±k). Ancak bir noktadan sonra kazanÃ§ azalÄ±r ve bu nokta optimal K olabilir.
FarklÄ± K deÄŸerleri iÃ§in WCSS (Within-Cluster Sum of Squares) hesaplanÄ±r.
WCSS, kÃ¼meler iÃ§indeki veri noktalarÄ±nÄ±n merkezlerine olan uzaklÄ±klarÄ±nÄ±n karesel toplamÄ±dÄ±r.
WCSS deÄŸerleri grafiÄŸe dÃ¶kÃ¼lÃ¼r, kÄ±rÄ±lma (dirsek) noktasÄ± optimal K deÄŸeridir.

Elbow yÃ¶nteminin yanÄ± sÄ±ra;

- Silhouette Score: Bir veri noktasÄ±nÄ±n kendi kÃ¼mesine olan yakÄ±nlÄ±ÄŸÄ± ile diÄŸer kÃ¼melere olan uzaklÄ±ÄŸÄ± karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.
Silhouette skoru+1â€™e yakÄ±nsa kÃ¼meler iyi ayrÄ±lmÄ±ÅŸtÄ±r, 0â€™a yakÄ±nsa kÃ¼meler karÄ±ÅŸmÄ±ÅŸtÄ±r, -1â€™e yakÄ±nsa yanlÄ±ÅŸ kÃ¼melenme vardÄ±r.
- Gap Statistic yÃ¶ntemi:GerÃ§ek veri seti ile rastgele daÄŸÄ±tÄ±lmÄ±ÅŸ veri setindeki kÃ¼meleme skorlarÄ± karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.
GerÃ§ek verideki kÃ¼meleme kalitesi rastgele veriye gÃ¶re en fazla arttÄ±ÄŸÄ±nda optimal K bulunur.
- Dendogram:  HiyerarÅŸik kÃ¼meleme sonucu dendrogram (aÄŸaÃ§ yapÄ±sÄ±) Ã§izilerek kÃ¼meler arasÄ± mesafeye gÃ¶re uygun K seÃ§ilir.
KesiÅŸim noktasÄ±,optimal kÃ¼me sayÄ±sÄ±nÄ± verir.


### KÃ¼melemede Standardizasyon Neden ve NasÄ±l YapÄ±lÄ±r?

Standardizasyon, kÃ¼meleme algoritmalarÄ±nÄ±n daha iyi performans gÃ¶stermesi iÃ§in veri setindeki Ã¶zellikleri ortak bir Ã¶lÃ§eÄŸe getirme iÅŸlemidir.
Ã–zellikle K-Means gibi Ã–klid mesafesi tabanlÄ± algoritmalarda bÃ¼yÃ¼k Ã¶lÃ§ekli deÄŸiÅŸkenler (Ã¶rneÄŸin "gelir" gibi bÃ¼yÃ¼k sayÄ±lar) kÃ¼Ã§Ã¼k Ã¶lÃ§ekli deÄŸiÅŸkenleri (Ã¶rneÄŸin "yaÅŸ") baskÄ±layabilir. Bu nedenle Ã¶zelliklerin farklÄ± Ã¶lÃ§eklerde olmasÄ± kÃ¼meleme sonuÃ§larÄ±nÄ± bozabilir.
KÃ¼meleme tek bir sÃ¼tuna gÃ¶re yapÄ±lmÄ±yor.BÃ¼yÃ¼k sayÄ±lar,kÃ¼melemeyi daha Ã§ok etkiliyor.
ElemanlarÄ±n,kÃ¼meye aidiyet oranlarÄ± farklÄ±dÄ±r.
SeÃ§ilen kÃ¼melerin yeni merkezi,yer deÄŸiÅŸtirmeler azalana kadardÄ±r.
Z-score standardizasyonu,min-max normalizasyonu,robust scaling gibi yÃ¶ntemlerle uygulanabilmektedir.
Standardizasyon yaparken sayÄ±larla deÄŸil,birimlerle oynuyoruz.
Bilgi geliyor,onu kÃ¼meye oturtuyoruz.
YapÄ±lan deÄŸiÅŸiklikler mutlaka label'da belirtilmelidir.
Bu iÅŸlem,mesafeye dayalÄ± algoritmalarÄ±n (K-Means, DBSCAN) performansÄ±nÄ± artÄ±rÄ±r.


### TPU(Tensor Processing Unit) nedir?
Google tarafÄ±ndan Ã¶zel olarak yapay zeka ve makine Ã¶ÄŸrenmesi iÅŸlemlerini hÄ±zlandÄ±rmak iÃ§in geliÅŸtirilen
bir donanÄ±m birimidir. 
Ã–zellikle TensorFlow kÃ¼tÃ¼phanesiyle uyumlu olacak ÅŸekilde optimize edilmiÅŸtir.
CPU ve GPU'lara kÄ±yasla daha hÄ±zlÄ± ve enerji verimli Ã§alÄ±ÅŸÄ±r.
Google Cloud TPU sayesinde uzaktan eriÅŸimle bÃ¼yÃ¼k Ã¶lÃ§ekli modeller eÄŸitilebilir.
GPU'lara kÄ±yasla daha az enerji tÃ¼keterek bÃ¼yÃ¼k verileri iÅŸleyebilir.

Veri setinde sÃ¼tun sayÄ±sÄ±nÄ± artÄ±rmak,Ã¶zellik sayÄ±sÄ±nÄ± artÄ±rmak anlamÄ±na gelir.Bu durum,daha iyi sonuÃ§ almamÄ±zÄ± saÄŸlar ancak iÅŸlem yÃ¼kÃ¼ artar.
Veri seti oluÅŸturulurken sÃ¼tun isimleri "en kÃ¼Ã§Ã¼k anlamlÄ± isimler" olmalÄ±dÄ±r.
Ã–rneÄŸin sÃ¼tun isimlerinin "BeÄŸeni SayÄ±sÄ±" ve "Yorum SayÄ±sÄ±" olmasÄ±ndansa "BeÄŸeni" ve "Yorum" ÅŸeklinde olmasÄ± tercih edilmelidir.

### Birine bir kitap verirken kitabÄ± kiÅŸiye gÃ¶re mi vereceÄŸiz yoksa kitaba gÃ¶re mi?
Burada Ã¶neri sistemleri ve birliktelik kurallarÄ± Ã¶ne Ã§Ä±kar.
Ã–neri sistemleri(recommendation systems):kullanÄ±cÄ± bazlÄ± bakÄ±ÅŸ aÃ§Ä±sÄ±.
Birliktelik kurallarÄ±(association rules):Ã¼rÃ¼n bazlÄ± bakÄ±ÅŸ aÃ§Ä±sÄ±.

## Decision Trees(Karar AÄŸaÃ§larÄ±)

Veri setindeki Ã¶zellikleri (features) kullanarak sÄ±nÄ±flandÄ±rma veya regresyon yapan bir makine Ã¶ÄŸrenmesi modelidir. AÄŸaÃ§ yapÄ±sÄ±nÄ± kullanarak veriyi dallara ayÄ±rÄ±r ve her dÃ¼ÄŸÃ¼mde bir karar verilir.
KÃ¶k dÃ¼ÄŸÃ¼m (Root Node): En iyi ayÄ±ran Ã¶zellik seÃ§ilir.
Dallanma (Branches): Veriye gÃ¶re dallara ayrÄ±lÄ±r.
Yaprak dÃ¼ÄŸÃ¼mler (Leaf Nodes): Son karar noktalarÄ±dÄ±r (sÄ±nÄ±f etiketi veya tahmin edilen deÄŸer).
Karar aÄŸacÄ± modelleri, hem sÄ±nÄ±flandÄ±rma hem regresyon problemlerinde gÃ¼Ã§lÃ¼ bir araÃ§tÄ±r.

Senkron programlama:Bir Ã¼st satÄ±rdaki kod bitmeden bir sonraki kod Ã§alÄ±ÅŸmaz.Asenkron programlamada ise buna gerek yoktur.

### Ders sÃ¼recinde deneyimlediÄŸimiz araÃ§lar:

1. ChatGPT: OpenAI tarafÄ±ndan geliÅŸtirilen, doÄŸal dil iÅŸleme (NLP) tekniklerini kullanan bir yapay zeka modelidir. 
2. Sider: YazÄ±lÄ±m geliÅŸtirme sÃ¼reÃ§lerinde, kodu otomatik olarak analiz eden ve hatalarÄ± tespit eden bir araÃ§ olarak kullanÄ±lÄ±r. 
3. Claude.ai: Claude, Anthropic adlÄ± bir yapay zeka ÅŸirketi tarafÄ±ndan geliÅŸtirilmiÅŸtir.DoÄŸal dil iÅŸleme (NLP) tekniklerini kullanarak metinleri anlamak ve Ã¼retmek iÃ§in tasarlanmÄ±ÅŸ bir yapay zeka modelidir. 
4. Gemini: Google DeepMind tarafÄ±ndan geliÅŸtirilen bir yapay zeka modelidir. DeepMind, Google'Ä±n yapay zeka araÅŸtÄ±rma laboratuvarÄ±dÄ±r ve Gemini, DeepMind'Ä±n GeliÅŸmiÅŸ Dil Modelleri alanÄ±ndaki son Ã§alÄ±ÅŸmalarÄ±ndan biridir.
5. Google AI Studio: Google'Ä±n yapay zeka (YZ) geliÅŸtirme ve eÄŸitme platformlarÄ±ndan biridir. Bu platform, kullanÄ±cÄ±larÄ±n yapay zeka modelleri oluÅŸturmasÄ±na, eÄŸitmesine ve daÄŸÄ±tmasÄ±na olanak tanÄ±r.KullanÄ±cÄ±larÄ±n AI Ã§Ã¶zÃ¼mleri geliÅŸtirmesini daha eriÅŸilebilir hale getirmeyi amaÃ§lar. Bu platformun, Ã¶zellikle veri bilimi, makine Ã¶ÄŸrenimi ve yapay zeka projelerinde profesyonellere bÃ¼yÃ¼k fayda saÄŸladÄ±ÄŸÄ± sÃ¶ylenebilir.
6. NotebookLM: Google'Ä±n sunduÄŸu yeni bir yapay zeka modelidir ve temelde Jupyter Notebook gibi interaktif ortamlarÄ± destekleyerek, doÄŸal dil iÅŸleme ve kod yazÄ±mÄ± gibi alanlarda yardÄ±mcÄ± olur. Bu model, Ã¶zellikle veri bilimcilerinin ve yazÄ±lÄ±mcÄ±larÄ±n verileri analiz etmek, kod yazmak ve Ã§eÅŸitli problemleri Ã§Ã¶zmek iÃ§in daha verimli bir ÅŸekilde Ã§alÄ±ÅŸmasÄ±nÄ± amaÃ§lar.
7. Cursor-The AI Code Editor: Yapay zeka ile kullanÄ±cÄ±larÄ±n daha etkin kod yazmasÄ±nÄ± saÄŸlar.
8. TensorFlow: Google tarafÄ±ndan geliÅŸtirilen ve aÃ§Ä±k kaynaklÄ± bir yapay zeka kÃ¼tÃ¼phanesidir. Derin Ã¶ÄŸrenme (deep learning) modelleri geliÅŸtirmek iÃ§in yaygÄ±n olarak kullanÄ±lÄ±r.
9. PyTorch: Facebook tarafÄ±ndan geliÅŸtirilen, Ã¶zellikle derin Ã¶ÄŸrenme modelleri iÃ§in yaygÄ±n olarak kullanÄ±lan aÃ§Ä±k kaynaklÄ± bir kÃ¼tÃ¼phanedir.
10. Keras:  Derin Ã¶ÄŸrenme modelleri iÃ§in yÃ¼ksek seviyeli bir API'dir ve TensorFlow Ã¼zerine inÅŸa edilmiÅŸtir. Keras, kullanÄ±mÄ± kolay APIâ€™leri ile model oluÅŸturmayÄ± hÄ±zlandÄ±rÄ±r.
11. Scikit-learn:  Python'da veri madenciliÄŸi ve makine Ã¶ÄŸrenimi iÃ§in en popÃ¼ler kÃ¼tÃ¼phanelerden biridir. Ä°statistiksel modeller, regresyon, sÄ±nÄ±flandÄ±rma ve kÃ¼meleme gibi gÃ¶revlerde kullanÄ±lÄ±r.
12. Pandas: Veri analizi ve manipÃ¼lasyonu iÃ§in kullanÄ±lan Python kÃ¼tÃ¼phanesidir.
13. Matplotlib ve Seaborn:Python'da veri gÃ¶rselleÅŸtirme iÃ§in kullanÄ±lan popÃ¼ler kÃ¼tÃ¼phanelerdir.
14. Google Colab: Google'Ä±n sunduÄŸu, Python kodlarÄ±nÄ± bulut Ã¼zerinde Ã§alÄ±ÅŸtÄ±rabileceÄŸiniz bir platformdur. GPU ve TPU desteÄŸi ile makine Ã¶ÄŸrenimi ve derin Ã¶ÄŸrenme modelleri Ã¼zerinde Ã§alÄ±ÅŸmak kolaylaÅŸÄ±r.
15. Git ve Github: Git, yazÄ±lÄ±m projelerindeki dosya deÄŸiÅŸikliklerini izleyen ve yÃ¶netmeye yarayan daÄŸÄ±tÄ±k bir sÃ¼rÃ¼m kontrol sistemidir, GitHub ise Git depolarÄ±nÄ± Ã§evrimiÃ§i olarak barÄ±ndÄ±ran ve iÅŸbirliÄŸi yapÄ±lmasÄ±nÄ± saÄŸlayan bir platformdur.
16. Hugging Face: Hugging Face, yapay zeka ve doÄŸal dil iÅŸleme (NLP) alanÄ±nda Ã¶ncÃ¼ bir platformdur ve kullanÄ±cÄ±larÄ±n dil modellerini kolayca eÄŸitmesini, paylaÅŸmasÄ±nÄ± ve kullanmasÄ±nÄ± saÄŸlar. Ã–zellikle aÃ§Ä±k kaynaklÄ± Transformers kÃ¼tÃ¼phanesi ile derin Ã¶ÄŸrenme modellerinin eriÅŸilebilirliÄŸini artÄ±rÄ±r.
17. Project IDX: Google tarafÄ±ndan geliÅŸtirilen bir entegre geliÅŸtirme ortamÄ± (IDE) platformudur. Bulut tabanlÄ± bu araÃ§, yazÄ±lÄ±mcÄ±lara uygulama geliÅŸtirme, test etme ve daÄŸÄ±tÄ±m sÃ¼reÃ§lerini hÄ±zlandÄ±rmak iÃ§in yapay zeka ve otomasyon destekli Ã¶zellikler sunar, bÃ¶ylece kullanÄ±cÄ±lar farklÄ± cihazlarda kod yazabilir ve projeleri kolayca yÃ¶netebilir.
18. Google Labs:  Google tarafÄ±ndan sunulan bir platformdur ve genellikle yeni ve deneysel Ã¼rÃ¼nlerin, teknolojilerin test edilip geliÅŸtirildiÄŸi bir ortamdÄ±r. KullanÄ±cÄ±lar, burada Googleâ€™Ä±n araÅŸtÄ±rma ve geliÅŸtirme aÅŸamasÄ±ndaki projeleriyle etkileÅŸime girebilir, yenilikÃ§i araÃ§lar ve hizmetlerle deney yapabilir. Google Labs, genellikle beta aÅŸamasÄ±ndaki Ã¼rÃ¼nleri denemek ve geri bildirim saÄŸlamak isteyen kullanÄ±cÄ±lar iÃ§in sunulur.
19. Streamlit: Python ile hÄ±zlÄ± bir ÅŸekilde web uygulamalarÄ± oluÅŸturmayÄ± saÄŸlayan aÃ§Ä±k kaynaklÄ± bir framework'tÃ¼r. Veri bilimcilerinin ve makine Ã¶ÄŸrenimi mÃ¼hendislerinin, projelerini gÃ¶rselleÅŸtirmek ve paylaÅŸmak iÃ§in minimum kodla etkileÅŸimli web uygulamalarÄ± geliÅŸtirmelerine olanak tanÄ±r. KullanÄ±cÄ±lar, veri gÃ¶rselleÅŸtirmeleri, model sonuÃ§larÄ± ve analizleri gÃ¶rsel olarak sunabilirler.
20. Gradio: Python ile hÄ±zlÄ± bir ÅŸekilde interaktif web arayÃ¼zleri oluÅŸturmayÄ± saÄŸlayan bir aÃ§Ä±k kaynaklÄ± kÃ¼tÃ¼phanedir. Ã–zellikle makine Ã¶ÄŸrenimi ve yapay zeka modellerini kullanÄ±cÄ± dostu bir ÅŸekilde sunmak iÃ§in kullanÄ±lÄ±r. Gradio, veri bilimcilerinin ve geliÅŸtiricilerinin modellerini hÄ±zlÄ±ca test etmelerine ve paylaÅŸmalarÄ±na olanak tanÄ±r.
21. Google Lens: Google tarafÄ±ndan geliÅŸtirilen bir gÃ¶rsel arama ve bilgi saÄŸlama uygulamasÄ±dÄ±r. KullanÄ±cÄ±lar, Lens ile telefonlarÄ±nÄ±n kameralarÄ±nÄ± kullanarak objeleri, metinleri, yerleri ve daha fazlasÄ±nÄ± tanÄ±yabilir ve bu nesneler hakkÄ±nda bilgi alabilirler.
22. Sora: OpenAI tarafÄ±ndan geliÅŸtirilen ve metin, resim veya mevcut videolarÄ± kullanarak kÄ±sa videolar oluÅŸturmanÄ±za olanak tanÄ±yan yapay zekÃ¢ destekli bir video Ã¼retim platformudur. Sora, kullanÄ±cÄ±larÄ±n hayal gÃ¼cÃ¼nÃ¼ gerÃ§eÄŸe dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in ileri dÃ¼zey analiz ve sentez teknolojileri kullanÄ±r.

#### "Modeli role sokmak" ne anlama gelir?

Veri biliminde "modeli role sokmak" ifadesi, genellikle eÄŸitilen bir modelin gerÃ§ek dÃ¼nyada kullanÄ±lacak ÅŸekilde devreye alÄ±nmasÄ± anlamÄ±na gelir. 
Bu, modelin eÄŸitim sÃ¼recinin tamamlanmasÄ±ndan sonra, gerÃ§ek verilerle Ã§alÄ±ÅŸmaya baÅŸlamasÄ± veya bir uygulama iÃ§inde etkin bir ÅŸekilde kullanÄ±lmasÄ±nÄ± ifade eder. 
Bu sÃ¼reÃ§, modelin "deployment" (daÄŸÄ±tÄ±mÄ±) olarak da adlandÄ±rÄ±labilir.


## Machine Learning Mesafeleri

Temel olarak Ã–klid mesafesi (Euclidean distance) kullanÄ±lsa da daha farklÄ± Ã¶lÃ§Ã¼mler de mevcuttur. 
Tek boyut iÃ§in Manhattan
2 boyut iÃ§in Euclidean(Ã–klid)
3,4,5 boyuta Ã§Ä±ktÄ±ÄŸÄ±nda ise Minkowski mesafesi kullanÄ±lÄ±yor.

Ã–klid,yÃ¼ksekliÄŸi yok sayar.Yani 3.boyutu ihmal eder.

## Yapay Sinir AÄŸlarÄ±(Artificial Neural Network)

Yapay sinir aÄŸlarÄ± (YSA), insan beyninin Ã¶zelliklerinden olan Ã¶ÄŸrenme yolu ile yeni bilgiler tÃ¼retebilme, yeni bilgiler oluÅŸturabilme ve keÅŸfedebilme gibi yetenekleri, herhangi bir yardÄ±m almadan otomatik olarak gerÃ§ekleÅŸtirebilmek amacÄ± ile geliÅŸtirilen bilgisayar sistemleridir.

Lineer regresyondan yapay sinir aÄŸlarÄ± oluÅŸuyor.(Derste ilk Ã¶ÄŸrendiÄŸimiz ve oldukÃ§a anlaÅŸÄ±labilir bir konu olan lineer regresyonun,yapay sinir aÄŸlarÄ± gibi karmaÅŸÄ±k bir konunun temelini oluÅŸturmasÄ± bizi Ã§ok ÅŸaÅŸÄ±rttÄ±.)
nÃ¶ron=fonksiyon.(ax+b'lerin her biri.b zorunlu deÄŸil,doÄŸrudan sapma yoksa b bulunmaz.)
baÄŸlantÄ±larÄ±n her biri=parametre(aÄŸÄ±rlÄ±k)
bunlarÄ±n bir araya geldiÄŸi hale "aÄŸ" denir.

Bir yapay sinir hÃ¼cresi beÅŸ bÃ¶lÃ¼mden oluÅŸmaktadÄ±r:

1. Girdiler: Girdiler nÃ¶ronlara gelen verilerdir. Bu girdilerden gelen veriler biyolojik sinir hÃ¼crelerinde olduÄŸu gibi toplanmak Ã¼zere nÃ¶ron Ã§ekirdeÄŸine gÃ¶nderilir.

2. AÄŸÄ±rlÄ±klar: Yapay sinir hÃ¼cresine gelen bilgiler girdiler Ã¼zerinden Ã§ekirdeÄŸe ulaÅŸmadan Ã¶nce geldikleri baÄŸlantÄ±larÄ±n aÄŸÄ±rlÄ±ÄŸÄ±yla Ã§arpÄ±larak Ã§ekirdeÄŸe iletilir. Bu sayede girdilerin Ã¼retilecek Ã§Ä±ktÄ± Ã¼zerindeki etkisi ayarlanabilinmektedir.

3.Toplama Fonksiyonu (BirleÅŸtirme Fonksiyonu): Toplama fonksiyonu bir yapay sinir hÃ¼cresine aÄŸÄ±rlÄ±klarla Ã§arpÄ±larak gelen girdileri toplayarak o hÃ¼crenin net girdisini hesaplayan bir fonksiyondur

4.Aktivasyon fonksiyonu: Ã–nceki katmandaki tÃ¼m girdilerin aÄŸÄ±rlÄ±klÄ± toplamÄ±nÄ± alan ve daha sonra bir Ã§Ä±kÄ±ÅŸ deÄŸeri (tipik olarak doÄŸrusal olmayan) Ã¼reten ve bir sonraki katmana geÃ§iren bir fonksiyondur. (Ã¶rneÄŸin, ReLU veya sigmoid ).

y=wx+b
Ãœst katmandaki her fonksiyon,alt katmandaki her fonksiyondan girdi alÄ±r.
Ã–rneÄŸin girdide b'yi dÃ¼zelttik ama Ã§Ä±ktÄ± deÄŸiÅŸmedi.Bu durumda b'nin hataya etkisi olmadÄ±ÄŸÄ±nÄ± gÃ¶rdÃ¼k.
Ä°lk katmanÄ±n girdileri dÄ±ÅŸ dÃ¼nyadan gelir.(Girdileri biz veririz).Fonksiyonlar ise 2.katmandan itibaren yazÄ±lÄ±r.
Kimin,fonksiyona ne kadar etkisi olduÄŸunu tÃ¼revle hesaplÄ±yoruz.

### Backpropagation(Geriye YayÄ±lÄ±m)

Bir yapay sinir aÄŸÄ±nÄ± eÄŸitmek iÃ§in kullanÄ±lan temel bir algoritmadÄ±r.
Bu yÃ¶ntem,aÄŸÄ±n Ã§Ä±ktÄ±sÄ± ile hedeflenen deÄŸer arasÄ±ndaki hatayÄ± minimize etmek iÃ§in aÄŸÄ±rlÄ±klarÄ± gÃ¼ncelleme iÅŸlemidir.Bu sÃ¼reÃ§te zincir kuralÄ± uygulanarak hata,geriye doÄŸru yayÄ±lÄ±r ve aÄŸÄ±n her katmanÄ±ndaki aÄŸÄ±rlÄ±klarÄ±n nasÄ±l gÃ¼ncellenmesi gerektiÄŸi hesaplanÄ±r.
Ã‡Ä±kan maliyetin,bu maliyete neden olan paydaÅŸlar Ã¼zerinden hesaplanmasÄ±dÄ±r.

Backpropagation AdÄ±mlarÄ±:
1. Ä°leri YayÄ±lÄ±m: GiriÅŸ verisi,aÄŸÄ±n giriÅŸ katmanÄ±na verilir.Her nÃ¶ronda aÄŸÄ±rlÄ±klÄ± toplama iÅŸlemi yapÄ±lÄ±r ve aktivasyon fonksiyonu(biz sigmoid fonksiyonu kullandÄ±k)uygulanÄ±r.Bu iÅŸlem,Ã§Ä±kÄ±ÅŸ katmanÄ±na kadar devam eder ve tahmin edilen Ã§Ä±ktÄ± elde edilir.
HatÄ±rlatma! Sigmoid fonksiyonu,giriÅŸ deÄŸerini [0,1] aralÄ±ÄŸÄ±na sÄ±kÄ±ÅŸtÄ±rÄ±r.

Ïƒ(x)=1/(1+e^-x) 
x burada giriÅŸ deÄŸeri.Ã‡Ä±ktÄ± her zaman 0 ve 1 arasÄ±nda olacak.
Ïƒ'(x)=Ïƒ(x)*(1-Ïƒ(x)) 
Geri yayÄ±lÄ±m sÄ±rasÄ±nda tÃ¼revler kolayca hesaplanÄ±r.

2. Hata Hesaplama: Tahmin edilen Ã§Ä±ktÄ±(YÃ§Ä±ktÄ±) ile gerÃ§ek deÄŸer(YgerÃ§ek) arasÄ±ndaki fark hesaplanÄ±r.Bu,genellikle bir kayÄ±p fonksiyonu aracÄ±lÄ±ÄŸÄ±yla yapÄ±lÄ±r.(MSE,Cross Entropy Loss gibi)
3. Hata Geriye YayÄ±lÄ±mÄ±: Hata,Ã§Ä±kÄ±ÅŸ katmanÄ±ndan baÅŸlayarak giriÅŸ katmanÄ±na doÄŸru geriye yayÄ±lÄ±r.Bu sÃ¼reÃ§te zincir kuralÄ± uygulanarak her katmandaki aÄŸÄ±rlÄ±klarÄ±n gradyanlarÄ± hesaplanÄ±r.
4. AÄŸÄ±rlÄ±klarÄ±n GÃ¼ncellenmesi: Hesaplanan gradyanlar kullanÄ±larak aÄŸÄ±rlÄ±klar gÃ¼ncellenir.learning rate(Ã¶ÄŸrenme oranÄ±)kullanÄ±lÄ±r.
5. AdÄ±mlarÄ±n TekrarlanmasÄ±: Bu iÅŸlemler,kayÄ±p fonksiyonu minimize edilene kadar veya belirlenen bir epoch sayÄ±sÄ±na ulaÅŸÄ±lana kadar tekrarlanÄ±r.

NOT: Backpropagation,sinir aÄŸlarÄ±nÄ± verimli bir ÅŸekilde eÄŸitmeye olanak tanÄ±r.Birden fazla gizli katmana sahip derin aÄŸlarda kullanÄ±lÄ±r.
